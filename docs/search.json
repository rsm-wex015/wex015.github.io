[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Wenxin(Wendy) Xu",
    "section": "",
    "text": "Welcome to my website"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "My Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nWenxin Xu\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project1/hw1_questions.html",
    "href": "projects/project1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#introduction",
    "href": "projects/project1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#data",
    "href": "projects/project1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nWe use the dataset made public by the authors, consisting of 50,083 prior donors who were randomly assigned into different treatment groups. The dataset contains variables indicating treatment status, donation behavior, suggested amounts, demographics, and political/geographic characteristics.\n\n\nSample Overview\n\nObservations: 50,083\nTreatments:\n\nControl\nMatching grants: $1:$1, $2:$1, $3:$1\n\nKey Outcomes:\n\ngave: whether the donor gave anything\namount: donation amount (if any)\n\nExample Variables:\n\nsize: suggested donation size (Unstated, $50, $100, etc.)\nredcty: lives in a red county\nhomestate: same state as charity ### Load and Preview the Data\n\n\n\nimport pandas as pd\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nWe test three pre-treatment variables: - Months since last donation (mrm2) - Highest previous contribution (hpa) - Number of prior donations (freq)\nThese variables should be similar across treatment and control groups if randomization was successful. We perform both t-tests and linear regressions for robustness. The table below summarizes the results.\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom scipy import stats\n\nbalance_vars = {\n    'Months Since Last Donation': 'mrm2',\n    'Highest Previous Contribution': 'hpa',\n    'Number of Prior Donations': 'freq'\n}\n\n# T-tests and OLS regressions\nttest_results = {}\nols_results = {}\n\nfor label, var in balance_vars.items():\n    control_vals = df[df['treatment'] == 0][var].dropna()\n    treatment_vals = df[df['treatment'] == 1][var].dropna()\n    t_stat, p_val = stats.ttest_ind(control_vals, treatment_vals, equal_var=False)\n    ttest_results[label] = {'t_stat': t_stat, 'p_val': p_val}\n\n    model = smf.ols(f\"{var} ~ treatment\", data=df).fit()\n    coef = model.params['treatment']\n    pval = model.pvalues['treatment']\n    ols_results[label] = {'coef': coef, 'p_val': pval}\n\n# Format for display\nbalance_summary = pd.DataFrame({\n    'Variable': list(balance_vars.keys()),\n    'T-test p-value': [ttest_results[v]['p_val'] for v in balance_vars],\n    'OLS coef on treatment': [ols_results[v]['coef'] for v in balance_vars],\n    'OLS p-value': [ols_results[v]['p_val'] for v in balance_vars]\n})\n\nbalance_summary\n\n\n\n\n\n\n\n\nVariable\nT-test p-value\nOLS coef on treatment\nOLS p-value\n\n\n\n\n0\nMonths Since Last Donation\n0.904855\n0.013686\n0.904886\n\n\n1\nHighest Previous Contribution\n0.331840\n0.637075\n0.345099\n\n\n2\nNumber of Prior Donations\n0.911740\n-0.011979\n0.911702\n\n\n\n\n\n\n\nThe balance test confirms that randomization worked as intended. Across the three pre-treatment variables — months since last donation, highest previous contribution, and number of prior donations — none show statistically significant differences between treatment and control groups at the 5% level. ﻿ This supports the internal validity of the experiment: any observed effects in giving behavior are unlikely to be due to baseline differences."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#experimental-results",
    "href": "projects/project1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nMatching Donations Increase Giving Probability\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\nWe compare the proportion of individuals who donated between the treatment group and the control group. This helps us understand whether the announcement of a matching gift increases the likelihood of donating.\n\nimport matplotlib.pyplot as plt\n\n# Calculate donation rates by group\ndonation_rates = df.groupby('treatment')['gave'].mean()\ndonation_rates.index = ['Control', 'Treatment']\n\n# Create bar plot\nfig, ax = plt.subplots(figsize=(6, 4))\nbars = ax.bar(donation_rates.index, donation_rates.values, width=0.5, color=['#4C72B0', '#55A868'])\n\n# Add percentage labels\nfor bar in bars:\n    height = bar.get_height()\n    ax.text(bar.get_x() + bar.get_width() / 2, height + 0.002,\n            f'{height:.2%}', ha='center', va='bottom', fontsize=10)\n\n# Formatting\nax.set_ylabel('Proportion Donated')\nax.set_title('Effect of Matching Gift on Donation Rate')\nax.set_ylim(0, max(donation_rates.values) + 0.03)\nax.grid(axis='y', linestyle='--', alpha=0.5)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe chart shows that individuals in the treatment group donated at a rate of 2.20%, compared to 1.79% in the control group — an increase of approximately 23% in relative terms. This result suggests that the announcement of a matching gift offer increases donor engagement, likely because donors feel their contribution has greater impact.\nThis initial analysis replicates the paper’s key finding: matching incentives effectively nudge donors into action.\n\n\nStatistical Significance: T-test and Linear Regression\nWe test whether the observed difference in donation behavior is statistically significant, using both a t-test and a bivariate regression.\n\nfrom scipy.stats import ttest_ind\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Group samples\ncontrol = df[df['treatment'] == 0]['gave']\ntreatment = df[df['treatment'] == 1]['gave']\n\n# T-test (unequal variance)\nt_stat, p_val = ttest_ind(treatment, control, equal_var=False)\n\n# OLS Regression\nmodel = smf.ols(\"gave ~ treatment\", data=df).fit()\nreg_summary = model.summary()\nprint(t_stat, p_val, reg_summary)\nprint(f\"T-statistic: {t_stat:.4f}, P-value: {p_val:.4f}\")\n\n3.2094621908279835 0.0013309823450914173                             OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):            0.00193\nTime:                        19:52:14   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nT-statistic: 3.2095, P-value: 0.0013\n\n\nBoth tests lead to the same conclusion:\nThe t-test indicates a statistically significant difference in mean donation rates between treatment and control (p-value &lt; 0.01). The regression coefficient on treatment is +0.0042, indicating that individuals in the treatment group were 0.42 percentage points more likely to donate, which is about a 23% increase over the control group mean of 1.79%. This finding is statistically significant (p = 0.002), and replicates the original result in Table 2a Panel A of Karlan and List (2007).\nBehavioral Insight When individuals are told that their contribution will be matched, they perceive their action as more impactful. This increases their willingness to give, even if the absolute probability of donation remains low. Matching gifts operate not only as a financial lever but also as a psychological motivator, increasing perceived effectiveness.\n\n\nProbit Model with Marginal Effects\nWhile the probit coefficient on treatment was 0.087, that number cannot be directly interpreted as a change in probability. So, we compute the marginal effect of treatment.\n\nprobit_model = sm.Probit(df['gave'], sm.add_constant(df['treatment'])).fit()\nmarginal_effects = probit_model.get_margeff()\nmarginal_effects.summary()\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\n\nProbit Marginal Effects\n\n\nDep. Variable:\ngave\n\n\nMethod:\ndydx\n\n\nAt:\noverall\n\n\n\n\n\n\n\n\n\ndy/dx\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\ntreatment\n0.0043\n0.001\n3.104\n0.002\n0.002\n0.007\n\n\n\n\n\nThe marginal effect of treatment is approximately 0.004, which means that receiving a matching offer increased the probability of donation by 0.4 percentage points — exactly what the original paper reports using a linear probability model. In this way, the Probit model gives us both a robust theoretical approach and a practically interpretable result."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#simulation-experiment",
    "href": "projects/project1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nTo simulate the LLN, we:\n\nDraw 10,000 Bernoulli samples from each group\nCalculate the difference in outcomes for each simulated pair\nPlot the cumulative average of the differences\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set probabilities\np_control = 0.018\np_treatment = 0.022\nn_draws = 10000\nnp.random.seed(42)\n\n# Simulate\ncontrol_draws = np.random.binomial(1, p_control, n_draws)\ntreatment_draws = np.random.binomial(1, p_treatment, n_draws)\n\n# Difference vector\ndifferences = treatment_draws - control_draws\ncumulative_avg_diff = np.cumsum(differences) / np.arange(1, n_draws + 1)\n\n# Plot\ntrue_diff = p_treatment - p_control\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg_diff, label='Cumulative Avg. of Differences', color='orange')\nplt.axhline(true_diff, color='red', linestyle='--', label='True Difference (0.004)')\nplt.title(\"Law of Large Numbers Simulation: Convergence to True Difference\")\nplt.xlabel(\"Simulation Iteration\")\nplt.ylabel(\"Difference in Donation Probability\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe simulation shows that the cumulative average of the differences converges to the true value of 0.004, which is the expected treatment effect. This is a visual and intuitive demonstration of the Law of Large Numbers: with more data, our sample statistics converge to population parameters.\nThis validates the logic behind the t-test and confirms why large samples allow for reliable estimation of small effects — just like in Karlan & List (2007), where a small increase in giving (from 1.8% to 2.2%) was detected across a large sample.\n\n\nCentral Limit Theorem\nTo visualize the Central Limit Theorem, we simulate 1,000 experiments for each of four sample sizes: 50, 200, 500, and 1000. In each simulation, we:\n\nDraw n observations from a Bernoulli(p=0.018) distribution (control group)\nDraw n from a Bernoulli(p=0.022) distribution (treatment group)\nCalculate the difference in sample means (treatment - control)\nRepeat 1,000 times and plot the histogram of these average differences\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.flatten()\n\nfor idx, n in enumerate(sample_sizes):\n    avg_diffs = [] \n    for _ in range(n_simulations):\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        diff = treatment_sample.mean() - control_sample.mean()\n        avg_diffs.append(diff)\n\n  \n    axes[idx].hist(avg_diffs, bins=30, color='skyblue', edgecolor='black')\n    axes[idx].axvline(0, color='red', linestyle='--', label='Zero')\n    axes[idx].set_title(f\"Sample Size = {n}\")\n    axes[idx].set_xlabel(\"Avg. Difference (Treatment - Control)\")\n    axes[idx].set_ylabel(\"Frequency\")\n    axes[idx].legend()\n\nplt.suptitle(\"Central Limit Theorem Simulation: Sampling Distributions of Avg. Differences\", fontsize=14)\nplt.tight_layout(rect=[0, 0, 1, 0.96])\nplt.show()\n\n\n\n\n\n\n\n\nThese histograms show that:\nAs sample size increases, the distribution of average differences becomes tighter and more symmetric For small sample sizes (e.g., n = 50), the histogram is more spread out and zero often appears near the center For larger sample sizes (n = 500 or 1000), the distribution concentrates around the true mean difference (~0.004), and zero moves closer to the edge or tail This behavior demonstrates the Central Limit Theorem in action:\nEven though the original data (Bernoulli) is highly skewed, the sampling distribution of the mean difference becomes approximately normal, and its variance shrinks with larger n. This validates why Karlan & List’s experiment was able to detect a small effect (2.2% vs 1.8%) — their large sample size ensured that sampling variation wouldn’t drown out the true effect."
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "Test",
    "section": "",
    "text": "Hello world!\nsummary(mtcars)"
  },
  {
    "objectID": "projects/project1/project1.html",
    "href": "projects/project1/project1.html",
    "title": "Wendy",
    "section": "",
    "text": "import pandas as pd\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom scipy import stats\n\nbalance_vars = {\n    'Months Since Last Donation': 'mrm2',\n    'Highest Previous Contribution': 'hpa',\n    'Number of Prior Donations': 'freq'\n}\n\n# T-tests and OLS regressions\nttest_results = {}\nols_results = {}\n\nfor label, var in balance_vars.items():\n    control_vals = df[df['treatment'] == 0][var].dropna()\n    treatment_vals = df[df['treatment'] == 1][var].dropna()\n    t_stat, p_val = stats.ttest_ind(control_vals, treatment_vals, equal_var=False)\n    ttest_results[label] = {'t_stat': t_stat, 'p_val': p_val}\n\n    model = smf.ols(f\"{var} ~ treatment\", data=df).fit()\n    coef = model.params['treatment']\n    pval = model.pvalues['treatment']\n    ols_results[label] = {'coef': coef, 'p_val': pval}\n\n# Format for display\nbalance_summary = pd.DataFrame({\n    'Variable': list(balance_vars.keys()),\n    'T-test p-value': [ttest_results[v]['p_val'] for v in balance_vars],\n    'OLS coef on treatment': [ols_results[v]['coef'] for v in balance_vars],\n    'OLS p-value': [ols_results[v]['p_val'] for v in balance_vars]\n})\n\nbalance_summary\n\n\n\n\n\n\n\n\nVariable\nT-test p-value\nOLS coef on treatment\nOLS p-value\n\n\n\n\n0\nMonths Since Last Donation\n0.904855\n0.013686\n0.904886\n\n\n1\nHighest Previous Contribution\n0.331840\n0.637075\n0.345099\n\n\n2\nNumber of Prior Donations\n0.911740\n-0.011979\n0.911702\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\n# Calculate donation rates\ndonation_rates = df.groupby('treatment')['gave'].mean()\ndonation_rates.index = ['Control', 'Treatment']\n\n# Create bar plot\nplt.figure(figsize=(6, 4))\nbars = plt.bar(donation_rates.index, donation_rates.values, width=0.5)\nplt.ylabel('Proportion Donated')\nplt.title('Donation Rates by Group')\n\n# Add percentage labels on top of bars\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2.0, height + 0.01,\n             f'{height:.2%}', ha='center', va='bottom')\n\nplt.ylim(0, max(donation_rates.values) + 0.05)\nplt.grid(axis='y', linestyle='--', alpha=0.6)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import ttest_ind\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# T-test\ncontrol_group = df[df['treatment'] == 0]['gave']\ntreatment_group = df[df['treatment'] == 1]['gave']\nt_stat, p_val = ttest_ind(treatment_group, control_group, equal_var=False)\n\n# Regression\nmodel = smf.ols(\"gave ~ treatment\", data=df).fit()\nreg_summary = model.summary()\n\nt_stat, p_val, reg_summary\n\n(np.float64(3.2094621908279835),\n np.float64(0.0013309823450914173),\n &lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                             OLS Regression Results                            \n ==============================================================================\n Dep. Variable:                   gave   R-squared:                       0.000\n Model:                            OLS   Adj. R-squared:                  0.000\n Method:                 Least Squares   F-statistic:                     9.618\n Date:                Mon, 21 Apr 2025   Prob (F-statistic):            0.00193\n Time:                        15:47:55   Log-Likelihood:                 26630.\n No. Observations:               50083   AIC:                        -5.326e+04\n Df Residuals:                   50081   BIC:                        -5.324e+04\n Df Model:                           1                                         \n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n ------------------------------------------------------------------------------\n Intercept      0.0179      0.001     16.225      0.000       0.016       0.020\n treatment      0.0042      0.001      3.101      0.002       0.002       0.007\n ==============================================================================\n Omnibus:                    59814.280   Durbin-Watson:                   2.005\n Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\n Skew:                           6.740   Prob(JB):                         0.00\n Kurtosis:                      46.440   Cond. No.                         3.23\n ==============================================================================\n \n Notes:\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n \"\"\")\n\n\n\nimport statsmodels.api as sm\n\nprobit_model = sm.Probit(df['gave'], sm.add_constant(df['treatment'])).fit()\n\n# 计算平均边际效应\nmarginal_effects = probit_model.get_margeff()\nmarginal_effects.summary()\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\n\nProbit Marginal Effects\n\n\nDep. Variable:\ngave\n\n\nMethod:\ndydx\n\n\nAt:\noverall\n\n\n\n\n\n\n\n\n\ndy/dx\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\ntreatment\n0.0043\n0.001\n3.104\n0.002\n0.002\n0.007\n\n\n\n\n\n\nfrom scipy.stats import ttest_ind\n\n# Only look at treatment group\ndf_match = df[df['treatment'] == 1]\n\n# Define match groups\ngave_1_1 = df_match[df_match['ratio'] == 1]['gave']\ngave_2_1 = df_match[df_match['ratio'] == 2]['gave']\ngave_3_1 = df_match[df_match['ratio'] == 3]['gave']\n\n# T-tests\nttest_2v1 = ttest_ind(gave_2_1, gave_1_1, equal_var=False)\nttest_3v1 = ttest_ind(gave_3_1, gave_1_1, equal_var=False)\n\nprint(\"2:1 vs 1:1 p-value:\", round(ttest_2v1.pvalue, 4))\nprint(\"3:1 vs 1:1 p-value:\", round(ttest_3v1.pvalue, 4))\n\n2:1 vs 1:1 p-value: 0.3345\n3:1 vs 1:1 p-value: 0.3101\n\n\n\nimport statsmodels.formula.api as smf\n\n# Filter treatment group only\ndf_match = df[df['treatment'] == 1]\n\n# Linear regression: 1:1 match is the omitted category\nmodel = smf.ols(\"gave ~ ratio2 + ratio3\", data=df_match).fit()\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\ngave\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.000\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.6454\n\n\nDate:\nMon, 21 Apr 2025\nProb (F-statistic):\n0.524\n\n\nTime:\n21:56:21\nLog-Likelihood:\n16688.\n\n\nNo. Observations:\n33396\nAIC:\n-3.337e+04\n\n\nDf Residuals:\n33393\nBIC:\n-3.334e+04\n\n\nDf Model:\n2\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n0.0207\n0.001\n14.912\n0.000\n0.018\n0.023\n\n\nratio2\n0.0019\n0.002\n0.958\n0.338\n-0.002\n0.006\n\n\nratio3\n0.0020\n0.002\n1.008\n0.313\n-0.002\n0.006\n\n\n\n\n\n\n\n\nOmnibus:\n38963.957\nDurbin-Watson:\n1.995\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n2506478.937\n\n\nSkew:\n6.511\nProb(JB):\n0.00\n\n\nKurtosis:\n43.394\nCond. No.\n3.73\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n# Mean donation rates by ratio\nmean_1_1 = df_match[df_match['ratio'] == 1]['gave'].mean()\nmean_2_1 = df_match[df_match['ratio'] == 2]['gave'].mean()\nmean_3_1 = df_match[df_match['ratio'] == 3]['gave'].mean()\n\ndiff_2v1 = mean_2_1 - mean_1_1\ndiff_3v2 = mean_3_1 - mean_2_1\n\nprint(\"Response rate (2:1 - 1:1):\", round(diff_2v1, 4))\nprint(\"Response rate (3:1 - 2:1):\", round(diff_3v2, 4))\n\nResponse rate (2:1 - 1:1): 0.0019\nResponse rate (3:1 - 2:1): 0.0001\n\n\n\n# Keep only donors\ndonated = df[df['gave'] == 1]\n\n# T-test: compare mean donation amounts\namount_treatment = donated[donated['treatment'] == 1]['amount']\namount_control = donated[donated['treatment'] == 0]['amount']\nfrom scipy.stats import ttest_ind\nt_stat, p_val = ttest_ind(amount_treatment, amount_control, equal_var=False)\n\n# Regression: amount ~ treatment\nimport statsmodels.formula.api as smf\nmodel_amount = smf.ols(\"amount ~ treatment\", data=donated).fit()\nmodel_amount.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\namount\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.001\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.3374\n\n\nDate:\nMon, 21 Apr 2025\nProb (F-statistic):\n0.561\n\n\nTime:\n22:07:00\nLog-Likelihood:\n-5326.8\n\n\nNo. Observations:\n1034\nAIC:\n1.066e+04\n\n\nDf Residuals:\n1032\nBIC:\n1.067e+04\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n45.5403\n2.423\n18.792\n0.000\n40.785\n50.296\n\n\ntreatment\n-1.6684\n2.872\n-0.581\n0.561\n-7.305\n3.968\n\n\n\n\n\n\n\n\nOmnibus:\n587.258\nDurbin-Watson:\n2.031\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n5623.279\n\n\nSkew:\n2.464\nProb(JB):\n0.00\n\n\nKurtosis:\n13.307\nCond. No.\n3.49\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\namount_control = df[df['treatment'] == 0]['amount']\namount_treatment = df[df['treatment'] == 1]['amount']\nttest_amount = ttest_ind(amount_treatment, amount_control, equal_var=False)\n\nmodel_amount = smf.ols(\"amount ~ treatment\", data=df).fit()\nttest_amount, model_amount.summary()\n\n(TtestResult(statistic=np.float64(1.9182618934467577), pvalue=np.float64(0.05508566528918335), df=np.float64(36216.05660774625)),\n &lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                             OLS Regression Results                            \n ==============================================================================\n Dep. Variable:                 amount   R-squared:                       0.000\n Model:                            OLS   Adj. R-squared:                  0.000\n Method:                 Least Squares   F-statistic:                     3.461\n Date:                Mon, 21 Apr 2025   Prob (F-statistic):             0.0628\n Time:                        22:09:56   Log-Likelihood:            -1.7946e+05\n No. Observations:               50083   AIC:                         3.589e+05\n Df Residuals:                   50081   BIC:                         3.589e+05\n Df Model:                           1                                         \n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n ------------------------------------------------------------------------------\n Intercept      0.8133      0.067     12.063      0.000       0.681       0.945\n treatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n ==============================================================================\n Omnibus:                    96861.113   Durbin-Watson:                   2.008\n Prob(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\n Skew:                          15.297   Prob(JB):                         0.00\n Kurtosis:                     341.269   Cond. No.                         3.23\n ==============================================================================\n \n Notes:\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n \"\"\")\n\n\n\ndf_positive = df[df['gave'] == 1]\nmodel_conditional = smf.ols(\"amount ~ treatment\", data=df_positive).fit()\nmodel_conditional.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\namount\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.001\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.3374\n\n\nDate:\nMon, 21 Apr 2025\nProb (F-statistic):\n0.561\n\n\nTime:\n22:15:55\nLog-Likelihood:\n-5326.8\n\n\nNo. Observations:\n1034\nAIC:\n1.066e+04\n\n\nDf Residuals:\n1032\nBIC:\n1.067e+04\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n45.5403\n2.423\n18.792\n0.000\n40.785\n50.296\n\n\ntreatment\n-1.6684\n2.872\n-0.581\n0.561\n-7.305\n3.968\n\n\n\n\n\n\n\n\nOmnibus:\n587.258\nDurbin-Watson:\n2.031\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n5623.279\n\n\nSkew:\n2.464\nProb(JB):\n0.00\n\n\nKurtosis:\n13.307\nCond. No.\n3.49\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nimport matplotlib.pyplot as plt\n\ndonated_control = df[(df['gave'] == 1) & (df['treatment'] == 0)]['amount']\ndonated_treatment = df[(df['gave'] == 1) & (df['treatment'] == 1)]['amount']\n\nmean_control = donated_control.mean()\nmean_treatment = donated_treatment.mean()\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\n# Control group\naxes[0].hist(donated_control, bins=20, color='skyblue', edgecolor='black')\naxes[0].axvline(mean_control, color='red', linestyle='dashed', linewidth=2)\naxes[0].set_title('Control Group (Donors Only)')\naxes[0].set_xlabel('Donation Amount')\naxes[0].set_ylabel('Frequency')\naxes[0].text(mean_control + 1, axes[0].get_ylim()[1] * 0.8,\n             f'Mean: ${mean_control:.2f}', color='red')\n\n# Treatment group\naxes[1].hist(donated_treatment, bins=20, color='lightgreen', edgecolor='black')\naxes[1].axvline(mean_treatment, color='red', linestyle='dashed', linewidth=2)\naxes[1].set_title('Treatment Group (Donors Only)')\naxes[1].set_xlabel('Donation Amount')\naxes[1].text(mean_treatment + 1, axes[1].get_ylim()[1] * 0.8,\n             f'Mean: ${mean_treatment:.2f}', color='red')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set probabilities\np_control = 0.018\np_treatment = 0.022\nn_draws = 10000\nnp.random.seed(42)\n\n# Simulate\ncontrol_draws = np.random.binomial(1, p_control, n_draws)\ntreatment_draws = np.random.binomial(1, p_treatment, n_draws)\n\n# Difference vector\ndifferences = treatment_draws - control_draws\ncumulative_avg_diff = np.cumsum(differences) / np.arange(1, n_draws + 1)\n\n# Plot\ntrue_diff = p_treatment - p_control\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg_diff, label='Cumulative Avg. of Differences', color='orange')\nplt.axhline(true_diff, color='red', linestyle='--', label='True Difference (0.004)')\nplt.title(\"Law of Large Numbers Simulation: Convergence to True Difference\")\nplt.xlabel(\"Simulation Iteration\")\nplt.ylabel(\"Difference in Donation Probability\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 固定随机种子以保证结果可复现\nnp.random.seed(42)\n\n# 设置参数\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\n# 创建子图容器\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.flatten()\n\n# 对每个样本量进行模拟\nfor idx, n in enumerate(sample_sizes):\n    avg_diffs = []  # 储存每次实验的均值差\n    for _ in range(n_simulations):\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        diff = treatment_sample.mean() - control_sample.mean()\n        avg_diffs.append(diff)\n\n    # 绘图\n    axes[idx].hist(avg_diffs, bins=30, color='skyblue', edgecolor='black')\n    axes[idx].axvline(0, color='red', linestyle='--', label='Zero')\n    axes[idx].set_title(f\"Sample Size = {n}\")\n    axes[idx].set_xlabel(\"Avg. Difference (Treatment - Control)\")\n    axes[idx].set_ylabel(\"Frequency\")\n    axes[idx].legend()\n\n# 总标题和布局\nplt.suptitle(\"Central Limit Theorem Simulation: Sampling Distributions of Avg. Differences\", fontsize=14)\nplt.tight_layout(rect=[0, 0, 1, 0.96])\nplt.show()"
  },
  {
    "objectID": "project1.html",
    "href": "project1.html",
    "title": "Wendy",
    "section": "",
    "text": "import pandas as pd\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom scipy import stats\n\nbalance_vars = {\n    'Months Since Last Donation': 'mrm2',\n    'Highest Previous Contribution': 'hpa',\n    'Number of Prior Donations': 'freq'\n}\n\n# T-tests and OLS regressions\nttest_results = {}\nols_results = {}\n\nfor label, var in balance_vars.items():\n    control_vals = df[df['treatment'] == 0][var].dropna()\n    treatment_vals = df[df['treatment'] == 1][var].dropna()\n    t_stat, p_val = stats.ttest_ind(control_vals, treatment_vals, equal_var=False)\n    ttest_results[label] = {'t_stat': t_stat, 'p_val': p_val}\n\n    model = smf.ols(f\"{var} ~ treatment\", data=df).fit()\n    coef = model.params['treatment']\n    pval = model.pvalues['treatment']\n    ols_results[label] = {'coef': coef, 'p_val': pval}\n\n# Format for display\nbalance_summary = pd.DataFrame({\n    'Variable': list(balance_vars.keys()),\n    'T-test p-value': [ttest_results[v]['p_val'] for v in balance_vars],\n    'OLS coef on treatment': [ols_results[v]['coef'] for v in balance_vars],\n    'OLS p-value': [ols_results[v]['p_val'] for v in balance_vars]\n})\n\nbalance_summary\n\n\n\n\n\n\n\n\nVariable\nT-test p-value\nOLS coef on treatment\nOLS p-value\n\n\n\n\n0\nMonths Since Last Donation\n0.904855\n0.013686\n0.904886\n\n\n1\nHighest Previous Contribution\n0.331840\n0.637075\n0.345099\n\n\n2\nNumber of Prior Donations\n0.911740\n-0.011979\n0.911702\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\n# Calculate donation rates\ndonation_rates = df.groupby('treatment')['gave'].mean()\ndonation_rates.index = ['Control', 'Treatment']\n\n# Create bar plot\nplt.figure(figsize=(6, 4))\nbars = plt.bar(donation_rates.index, donation_rates.values, width=0.5)\nplt.ylabel('Proportion Donated')\nplt.title('Donation Rates by Group')\n\n# Add percentage labels on top of bars\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2.0, height + 0.01,\n             f'{height:.2%}', ha='center', va='bottom')\n\nplt.ylim(0, max(donation_rates.values) + 0.05)\nplt.grid(axis='y', linestyle='--', alpha=0.6)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import ttest_ind\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# T-test\ncontrol_group = df[df['treatment'] == 0]['gave']\ntreatment_group = df[df['treatment'] == 1]['gave']\nt_stat, p_val = ttest_ind(treatment_group, control_group, equal_var=False)\n\n# Regression\nmodel = smf.ols(\"gave ~ treatment\", data=df).fit()\nreg_summary = model.summary()\n\nt_stat, p_val, reg_summary\n\n(np.float64(3.2094621908279835),\n np.float64(0.0013309823450914173),\n &lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                             OLS Regression Results                            \n ==============================================================================\n Dep. Variable:                   gave   R-squared:                       0.000\n Model:                            OLS   Adj. R-squared:                  0.000\n Method:                 Least Squares   F-statistic:                     9.618\n Date:                Mon, 21 Apr 2025   Prob (F-statistic):            0.00193\n Time:                        15:47:55   Log-Likelihood:                 26630.\n No. Observations:               50083   AIC:                        -5.326e+04\n Df Residuals:                   50081   BIC:                        -5.324e+04\n Df Model:                           1                                         \n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n ------------------------------------------------------------------------------\n Intercept      0.0179      0.001     16.225      0.000       0.016       0.020\n treatment      0.0042      0.001      3.101      0.002       0.002       0.007\n ==============================================================================\n Omnibus:                    59814.280   Durbin-Watson:                   2.005\n Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\n Skew:                           6.740   Prob(JB):                         0.00\n Kurtosis:                      46.440   Cond. No.                         3.23\n ==============================================================================\n \n Notes:\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n \"\"\")\n\n\n\nimport statsmodels.api as sm\n\nprobit_model = sm.Probit(df['gave'], sm.add_constant(df['treatment'])).fit()\n\n# 计算平均边际效应\nmarginal_effects = probit_model.get_margeff()\nmarginal_effects.summary()\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\n\nProbit Marginal Effects\n\n\nDep. Variable:\ngave\n\n\nMethod:\ndydx\n\n\nAt:\noverall\n\n\n\n\n\n\n\n\n\ndy/dx\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\ntreatment\n0.0043\n0.001\n3.104\n0.002\n0.002\n0.007\n\n\n\n\n\n\nfrom scipy.stats import ttest_ind\n\n# Only look at treatment group\ndf_match = df[df['treatment'] == 1]\n\n# Define match groups\ngave_1_1 = df_match[df_match['ratio'] == 1]['gave']\ngave_2_1 = df_match[df_match['ratio'] == 2]['gave']\ngave_3_1 = df_match[df_match['ratio'] == 3]['gave']\n\n# T-tests\nttest_2v1 = ttest_ind(gave_2_1, gave_1_1, equal_var=False)\nttest_3v1 = ttest_ind(gave_3_1, gave_1_1, equal_var=False)\n\nprint(\"2:1 vs 1:1 p-value:\", round(ttest_2v1.pvalue, 4))\nprint(\"3:1 vs 1:1 p-value:\", round(ttest_3v1.pvalue, 4))\n\n2:1 vs 1:1 p-value: 0.3345\n3:1 vs 1:1 p-value: 0.3101\n\n\n\nimport statsmodels.formula.api as smf\n\n# Filter treatment group only\ndf_match = df[df['treatment'] == 1]\n\n# Linear regression: 1:1 match is the omitted category\nmodel = smf.ols(\"gave ~ ratio2 + ratio3\", data=df_match).fit()\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\ngave\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.000\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.6454\n\n\nDate:\nMon, 21 Apr 2025\nProb (F-statistic):\n0.524\n\n\nTime:\n21:56:21\nLog-Likelihood:\n16688.\n\n\nNo. Observations:\n33396\nAIC:\n-3.337e+04\n\n\nDf Residuals:\n33393\nBIC:\n-3.334e+04\n\n\nDf Model:\n2\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n0.0207\n0.001\n14.912\n0.000\n0.018\n0.023\n\n\nratio2\n0.0019\n0.002\n0.958\n0.338\n-0.002\n0.006\n\n\nratio3\n0.0020\n0.002\n1.008\n0.313\n-0.002\n0.006\n\n\n\n\n\n\n\n\nOmnibus:\n38963.957\nDurbin-Watson:\n1.995\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n2506478.937\n\n\nSkew:\n6.511\nProb(JB):\n0.00\n\n\nKurtosis:\n43.394\nCond. No.\n3.73\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n# Mean donation rates by ratio\nmean_1_1 = df_match[df_match['ratio'] == 1]['gave'].mean()\nmean_2_1 = df_match[df_match['ratio'] == 2]['gave'].mean()\nmean_3_1 = df_match[df_match['ratio'] == 3]['gave'].mean()\n\ndiff_2v1 = mean_2_1 - mean_1_1\ndiff_3v2 = mean_3_1 - mean_2_1\n\nprint(\"Response rate (2:1 - 1:1):\", round(diff_2v1, 4))\nprint(\"Response rate (3:1 - 2:1):\", round(diff_3v2, 4))\n\nResponse rate (2:1 - 1:1): 0.0019\nResponse rate (3:1 - 2:1): 0.0001\n\n\n\n# Keep only donors\ndonated = df[df['gave'] == 1]\n\n# T-test: compare mean donation amounts\namount_treatment = donated[donated['treatment'] == 1]['amount']\namount_control = donated[donated['treatment'] == 0]['amount']\nfrom scipy.stats import ttest_ind\nt_stat, p_val = ttest_ind(amount_treatment, amount_control, equal_var=False)\n\n# Regression: amount ~ treatment\nimport statsmodels.formula.api as smf\nmodel_amount = smf.ols(\"amount ~ treatment\", data=donated).fit()\nmodel_amount.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\namount\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.001\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.3374\n\n\nDate:\nMon, 21 Apr 2025\nProb (F-statistic):\n0.561\n\n\nTime:\n22:07:00\nLog-Likelihood:\n-5326.8\n\n\nNo. Observations:\n1034\nAIC:\n1.066e+04\n\n\nDf Residuals:\n1032\nBIC:\n1.067e+04\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n45.5403\n2.423\n18.792\n0.000\n40.785\n50.296\n\n\ntreatment\n-1.6684\n2.872\n-0.581\n0.561\n-7.305\n3.968\n\n\n\n\n\n\n\n\nOmnibus:\n587.258\nDurbin-Watson:\n2.031\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n5623.279\n\n\nSkew:\n2.464\nProb(JB):\n0.00\n\n\nKurtosis:\n13.307\nCond. No.\n3.49\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\namount_control = df[df['treatment'] == 0]['amount']\namount_treatment = df[df['treatment'] == 1]['amount']\nttest_amount = ttest_ind(amount_treatment, amount_control, equal_var=False)\n\nmodel_amount = smf.ols(\"amount ~ treatment\", data=df).fit()\nttest_amount, model_amount.summary()\n\n(TtestResult(statistic=np.float64(1.9182618934467577), pvalue=np.float64(0.05508566528918335), df=np.float64(36216.05660774625)),\n &lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                             OLS Regression Results                            \n ==============================================================================\n Dep. Variable:                 amount   R-squared:                       0.000\n Model:                            OLS   Adj. R-squared:                  0.000\n Method:                 Least Squares   F-statistic:                     3.461\n Date:                Mon, 21 Apr 2025   Prob (F-statistic):             0.0628\n Time:                        22:09:56   Log-Likelihood:            -1.7946e+05\n No. Observations:               50083   AIC:                         3.589e+05\n Df Residuals:                   50081   BIC:                         3.589e+05\n Df Model:                           1                                         \n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n ------------------------------------------------------------------------------\n Intercept      0.8133      0.067     12.063      0.000       0.681       0.945\n treatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n ==============================================================================\n Omnibus:                    96861.113   Durbin-Watson:                   2.008\n Prob(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\n Skew:                          15.297   Prob(JB):                         0.00\n Kurtosis:                     341.269   Cond. No.                         3.23\n ==============================================================================\n \n Notes:\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n \"\"\")\n\n\n\ndf_positive = df[df['gave'] == 1]\nmodel_conditional = smf.ols(\"amount ~ treatment\", data=df_positive).fit()\nmodel_conditional.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\namount\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.001\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.3374\n\n\nDate:\nMon, 21 Apr 2025\nProb (F-statistic):\n0.561\n\n\nTime:\n22:15:55\nLog-Likelihood:\n-5326.8\n\n\nNo. Observations:\n1034\nAIC:\n1.066e+04\n\n\nDf Residuals:\n1032\nBIC:\n1.067e+04\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n45.5403\n2.423\n18.792\n0.000\n40.785\n50.296\n\n\ntreatment\n-1.6684\n2.872\n-0.581\n0.561\n-7.305\n3.968\n\n\n\n\n\n\n\n\nOmnibus:\n587.258\nDurbin-Watson:\n2.031\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n5623.279\n\n\nSkew:\n2.464\nProb(JB):\n0.00\n\n\nKurtosis:\n13.307\nCond. No.\n3.49\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nimport matplotlib.pyplot as plt\n\ndonated_control = df[(df['gave'] == 1) & (df['treatment'] == 0)]['amount']\ndonated_treatment = df[(df['gave'] == 1) & (df['treatment'] == 1)]['amount']\n\nmean_control = donated_control.mean()\nmean_treatment = donated_treatment.mean()\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\n# Control group\naxes[0].hist(donated_control, bins=20, color='skyblue', edgecolor='black')\naxes[0].axvline(mean_control, color='red', linestyle='dashed', linewidth=2)\naxes[0].set_title('Control Group (Donors Only)')\naxes[0].set_xlabel('Donation Amount')\naxes[0].set_ylabel('Frequency')\naxes[0].text(mean_control + 1, axes[0].get_ylim()[1] * 0.8,\n             f'Mean: ${mean_control:.2f}', color='red')\n\n# Treatment group\naxes[1].hist(donated_treatment, bins=20, color='lightgreen', edgecolor='black')\naxes[1].axvline(mean_treatment, color='red', linestyle='dashed', linewidth=2)\naxes[1].set_title('Treatment Group (Donors Only)')\naxes[1].set_xlabel('Donation Amount')\naxes[1].text(mean_treatment + 1, axes[1].get_ylim()[1] * 0.8,\n             f'Mean: ${mean_treatment:.2f}', color='red')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set probabilities\np_control = 0.018\np_treatment = 0.022\nn_draws = 10000\nnp.random.seed(42)\n\n# Simulate\ncontrol_draws = np.random.binomial(1, p_control, n_draws)\ntreatment_draws = np.random.binomial(1, p_treatment, n_draws)\n\n# Difference vector\ndifferences = treatment_draws - control_draws\ncumulative_avg_diff = np.cumsum(differences) / np.arange(1, n_draws + 1)\n\n# Plot\ntrue_diff = p_treatment - p_control\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg_diff, label='Cumulative Avg. of Differences', color='orange')\nplt.axhline(true_diff, color='red', linestyle='--', label='True Difference (0.004)')\nplt.title(\"Law of Large Numbers Simulation: Convergence to True Difference\")\nplt.xlabel(\"Simulation Iteration\")\nplt.ylabel(\"Difference in Donation Probability\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 固定随机种子以保证结果可复现\nnp.random.seed(42)\n\n# 设置参数\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\n# 创建子图容器\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.flatten()\n\n# 对每个样本量进行模拟\nfor idx, n in enumerate(sample_sizes):\n    avg_diffs = []  # 储存每次实验的均值差\n    for _ in range(n_simulations):\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        diff = treatment_sample.mean() - control_sample.mean()\n        avg_diffs.append(diff)\n\n    # 绘图\n    axes[idx].hist(avg_diffs, bins=30, color='skyblue', edgecolor='black')\n    axes[idx].axvline(0, color='red', linestyle='--', label='Zero')\n    axes[idx].set_title(f\"Sample Size = {n}\")\n    axes[idx].set_xlabel(\"Avg. Difference (Treatment - Control)\")\n    axes[idx].set_ylabel(\"Frequency\")\n    axes[idx].legend()\n\n# 总标题和布局\nplt.suptitle(\"Central Limit Theorem Simulation: Sampling Distributions of Avg. Differences\", fontsize=14)\nplt.tight_layout(rect=[0, 0, 1, 0.96])\nplt.show()"
  },
  {
    "objectID": "projects/project1/hw1_questions.html#abstract",
    "href": "projects/project1/hw1_questions.html#abstract",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Abstract",
    "text": "Abstract\nThis project seeks to replicate and interpret results from Karlan and List’s (2007) influential field experiment, which examined whether matching donations increase charitable giving. Over 50,000 prior donors were randomly assigned to receive direct mail with either no matching offer (control) or one of three matching grant treatments: $1:$1, $2:$1, or $3:$1.\nThe goal of this replication is to reproduce the study’s main empirical findings using the original dataset, explore the impact of different match ratios on both response rates and donation amounts, and provide insights relevant for fundraising practitioners."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#do-higher-matching-ratios-boost-giving",
    "href": "projects/project1/hw1_questions.html#do-higher-matching-ratios-boost-giving",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Do Higher Matching Ratios Boost Giving?",
    "text": "Do Higher Matching Ratios Boost Giving?\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nWe use a series of t-tests to compare whether people are more likely to donate under higher match ratios ($2:$1 or $3:$1) compared to the standard $1:$1 match ratio. This allows us to test whether larger matching incentives increase giving behavior.\n\nfrom scipy.stats import ttest_ind\n\n# Only include treatment group\ndf_match = df[df['treatment'] == 1]\n\n# Subgroup donation outcomes\ngave_1_1 = df_match[df_match['ratio'] == 1]['gave']\ngave_2_1 = df_match[df_match['ratio'] == 2]['gave']\ngave_3_1 = df_match[df_match['ratio'] == 3]['gave']\n\n# Compute means\nmean_1_1, mean_2_1, mean_3_1 = gave_1_1.mean(), gave_2_1.mean(), gave_3_1.mean()\n\n# T-tests: compare to 1:1\nttest_2v1 = ttest_ind(gave_2_1, gave_1_1, equal_var=False)\nttest_3v1 = ttest_ind(gave_3_1, gave_1_1, equal_var=False)\n\n# Output results\nprint(f\"Mean donation rates — 1:1: {mean_1_1:.4%}, 2:1: {mean_2_1:.4%}, 3:1: {mean_3_1:.4%}\")\nprint(\"2:1 vs 1:1 p-value:\", round(ttest_2v1.pvalue, 4))\nprint(\"3:1 vs 1:1 p-value:\", round(ttest_3v1.pvalue, 4))\n\nMean donation rates — 1:1: 2.0749%, 2:1: 2.2633%, 3:1: 2.2733%\n2:1 vs 1:1 p-value: 0.3345\n3:1 vs 1:1 p-value: 0.3101\n\n\nDespite slightly higher average donation rates in the 2:1 and 3:1 groups, neither difference is statistically significant. In other words, larger match offers did not significantly outperform the $1:$1 offer.\nIn essence, the act of announcing a match — any match — appears to be the key driver of increased giving. Donors respond to the presence of a match, not the generosity of its ratio. Once the match “feels impactful enough,” increasing the multiplier adds little marginal psychological value. This confirms the authors’ interpretation in the paper: “Larger match ratios had no additional impact.” (Page 8, Karlan & List 2007)"
  },
  {
    "objectID": "projects/project1/hw1_questions.html#regression-match-ratio-effects-on-giving",
    "href": "projects/project1/hw1_questions.html#regression-match-ratio-effects-on-giving",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Regression: Match Ratio Effects on Giving",
    "text": "Regression: Match Ratio Effects on Giving\nTo further assess whether larger match ratios increase donation behavior, we estimate a regression model where we compare 2:1 and 3:1 match rates to the baseline 1:1 match rate.\n\nimport statsmodels.formula.api as smf\n\n# Filter treatment group only\ndf_match = df[df['treatment'] == 1]\n\n# Estimate linear model: 1:1 match is omitted category\nmodel = smf.ols(\"gave ~ ratio2 + ratio3\", data=df_match).fit()\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\ngave\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.000\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.6454\n\n\nDate:\nWed, 23 Apr 2025\nProb (F-statistic):\n0.524\n\n\nTime:\n19:52:14\nLog-Likelihood:\n16688.\n\n\nNo. Observations:\n33396\nAIC:\n-3.337e+04\n\n\nDf Residuals:\n33393\nBIC:\n-3.334e+04\n\n\nDf Model:\n2\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n0.0207\n0.001\n14.912\n0.000\n0.018\n0.023\n\n\nratio2\n0.0019\n0.002\n0.958\n0.338\n-0.002\n0.006\n\n\nratio3\n0.0020\n0.002\n1.008\n0.313\n-0.002\n0.006\n\n\n\n\n\n\n\n\nOmnibus:\n38963.957\nDurbin-Watson:\n1.995\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n2506478.937\n\n\nSkew:\n6.511\nProb(JB):\n0.00\n\n\nKurtosis:\n43.394\nCond. No.\n3.73\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nThis regression estimates how larger matching ratios affect the probability of donating.\nThe intercept (0.0207) represents the average donation rate for the 1:1 match group — about 2.1%. The coefficient on ratio2 (2:1 match) is +0.0019, and the coefficient on ratio3 (3:1 match) is +0.0020. However, both of these coefficients are statistically insignificant (p-values &gt; 0.3), meaning that we cannot rule out that they are due to random chance.\nThese results reinforce what we observed in the t-tests and what Karlan & List (2007) emphasize in their paper: “Larger match ratios had no additional impact.” (Page 8)\nPeople are clearly responsive to the existence of a matching offer, but not its size. The match seems to function more like a binary psychological cue — a “yes/no” motivator — rather than a finely calibrated economic incentive.\nIn practice, this means that offering a 2:1 or 3:1 match does not significantly improve participation beyond what a 1:1 match already achieves. For fundraisers, this suggests that costlier match ratios may not provide additional return in response rate.\n\nResponse Rate Differences by Match Ratio\nWe now compute the response rate difference (i.e., difference in donation probability) between the match ratios using two methods: 1. Directly from the data 2. Using the fitted coefficients from the regression\n\nMethod 1: Directly from the data\n\n# Mean donation rates by ratio\nmean_1_1 = df_match[df_match['ratio'] == 1]['gave'].mean()\nmean_2_1 = df_match[df_match['ratio'] == 2]['gave'].mean()\nmean_3_1 = df_match[df_match['ratio'] == 3]['gave'].mean()\n\ndiff_2v1 = mean_2_1 - mean_1_1\ndiff_3v2 = mean_3_1 - mean_2_1\n\nprint(\"Response rate (2:1 - 1:1):\", round(diff_2v1, 4))\nprint(\"Response rate (3:1 - 2:1):\", round(diff_3v2, 4))\n\nResponse rate (2:1 - 1:1): 0.0019\nResponse rate (3:1 - 2:1): 0.0001\n\n\n\n\nMethod 2: Using regression coefficients\nRecall from the earlier regression:\nIntercept (1:1): 0.0207\nratio2 coefficient: +0.0019\nratio3 coefficient: +0.0020\nSo:\n2:1 - 1:1 = 0.0019\n3:1 - 2:1 = 0.0020 - 0.0019 = 0.0001\nBoth approaches yield nearly identical results:\nMoving from 1:1 to 2:1 increases the response rate by only 0.19–0.20 percentage points\nMoving from 2:1 to 3:1 increases the response rate by just 0.01 percentage points\nThese differences are statistically insignificant and extremely small. This reinforces our earlier conclusion that larger match ratios do not meaningfully increase participation. The psychological presence of a match seems to matter more than its actual size."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#size-of-charitable-contribution",
    "href": "projects/project1/hw1_questions.html#size-of-charitable-contribution",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Size of Charitable Contribution",
    "text": "Size of Charitable Contribution\nIn this subsection, we analyze whether the presence of a matching offer influences the size of the charitable donation, conditional on a donation being made.\nWe compare donation amounts between treatment and control groups using both a t-test and a bivariate linear regression.\n\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Split donation amount by treatment status\namount_control = df[df['treatment'] == 0]['amount']\namount_treatment = df[df['treatment'] == 1]['amount']\n\n# T-test for amount differences\nttest_amount = ttest_ind(amount_treatment, amount_control, equal_var=False)\n\n# Linear regression: donation amount ~ treatment\nmodel_amount = smf.ols(\"amount ~ treatment\", data=df).fit()\nttest_amount, model_amount.summary()\n\n(TtestResult(statistic=np.float64(1.9182618934467577), pvalue=np.float64(0.05508566528918335), df=np.float64(36216.05660774625)),\n &lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                             OLS Regression Results                            \n ==============================================================================\n Dep. Variable:                 amount   R-squared:                       0.000\n Model:                            OLS   Adj. R-squared:                  0.000\n Method:                 Least Squares   F-statistic:                     3.461\n Date:                Wed, 23 Apr 2025   Prob (F-statistic):             0.0628\n Time:                        19:52:14   Log-Likelihood:            -1.7946e+05\n No. Observations:               50083   AIC:                         3.589e+05\n Df Residuals:                   50081   BIC:                         3.589e+05\n Df Model:                           1                                         \n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n ------------------------------------------------------------------------------\n Intercept      0.8133      0.067     12.063      0.000       0.681       0.945\n treatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n ==============================================================================\n Omnibus:                    96861.113   Durbin-Watson:                   2.008\n Prob(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\n Skew:                          15.297   Prob(JB):                         0.00\n Kurtosis:                     341.269   Cond. No.                         3.23\n ==============================================================================\n \n Notes:\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n \"\"\")\n\n\nThe t-test yields a p-value of approximately 0.055, just above the standard 0.05 significance threshold. The regression model estimates that individuals in the treatment group give on average $0.15 more, with a p-value of 0.063. Both results suggest a positive but marginally insignificant effect.\nThese results provide an important nuance: While the matching offer increases the likelihood of giving, its effect on how much people give is less certain.\nSome individuals may be nudged into donating, but the size of the gift remains unaffected — or possibly even lower due to anchoring or tokenism (giving just enough to meet a perceived match).\nThis distinction underscores an important insight:\nParticipation and generosity may be driven by different behavioral mechanisms. Matching incentives are effective in getting people to act, but don’t necessarily increase the amount they give once they decide to give. From a fundraising perspective, this tells us that match incentives work best for increasing reach, not necessarily for maximizing revenue per donor."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#conditional-on-donating-did-people-give-more",
    "href": "projects/project1/hw1_questions.html#conditional-on-donating-did-people-give-more",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Conditional on Donating: Did People Give More?",
    "text": "Conditional on Donating: Did People Give More?\nTo investigate whether the matching offer influences how much people give, we now restrict our analysis to only those individuals who made a donation. This allows us to analyze donation amounts conditional on giving.\n\ndf_positive = df[df['gave'] == 1]\nmodel_conditional = smf.ols(\"amount ~ treatment\", data=df_positive).fit()\nmodel_conditional.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\namount\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.001\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.3374\n\n\nDate:\nWed, 23 Apr 2025\nProb (F-statistic):\n0.561\n\n\nTime:\n19:52:14\nLog-Likelihood:\n-5326.8\n\n\nNo. Observations:\n1034\nAIC:\n1.066e+04\n\n\nDf Residuals:\n1032\nBIC:\n1.067e+04\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n45.5403\n2.423\n18.792\n0.000\n40.785\n50.296\n\n\ntreatment\n-1.6684\n2.872\n-0.581\n0.561\n-7.305\n3.968\n\n\n\n\n\n\n\n\nOmnibus:\n587.258\nDurbin-Watson:\n2.031\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n5623.279\n\n\nSkew:\n2.464\nProb(JB):\n0.00\n\n\nKurtosis:\n13.307\nCond. No.\n3.49\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nThis regression estimates how the presence of a matching offer affects the size of the donation, among those who chose to give. The intercept (45.54) represents the average donation in the control group. The coefficient on treatment (-1.67) suggests that treated individuals gave slightly less on average — about $1.67 — but this effect is not statistically significant (p = 0.561).\nDoes This Have a Causal Interpretation?\nNo — and caution is warranted. While the original treatment assignment was randomized, this regression is conditional on donation behavior, which is a post-treatment variable. By analyzing only those who gave, we introduce selection bias — the two groups (treatment vs. control) are no longer directly comparable.\nMatching offers increase the probability of giving, as we’ve shown earlier. But among those who give, there is no significant difference in how much they donate. This suggests that matching incentives motivate action, but may not influence the donation amount once the decision to give is made. From a behavioral standpoint, this distinction is critical:\nParticipation and generosity are driven by different psychological forces. Matching works well to prompt giving — but not necessarily larger gifts.\nIf the goal is to maximize the number of donors, matching offers are effective. If the goal is to increase the average gift size, you may need a different strategy — such as social comparison, goal framing, or tiered benefits.\n\nDistribution of Donation Amounts (Donors Only)\nWe now visualize the distribution of donation amounts only among those who gave, separately for the treatment and control groups.\n\nimport matplotlib.pyplot as plt\n\ndonated_control = df[(df['gave'] == 1) & (df['treatment'] == 0)]['amount']\ndonated_treatment = df[(df['gave'] == 1) & (df['treatment'] == 1)]['amount']\n\nmean_control = donated_control.mean()\nmean_treatment = donated_treatment.mean()\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\n# Control group\naxes[0].hist(donated_control, bins=20, color='skyblue', edgecolor='black')\naxes[0].axvline(mean_control, color='red', linestyle='dashed', linewidth=2)\naxes[0].set_title('Control Group (Donors Only)')\naxes[0].set_xlabel('Donation Amount')\naxes[0].set_ylabel('Frequency')\naxes[0].text(mean_control + 1, axes[0].get_ylim()[1] * 0.8,\n             f'Mean: ${mean_control:.2f}', color='red')\n\n# Treatment group\naxes[1].hist(donated_treatment, bins=20, color='lightgreen', edgecolor='black')\naxes[1].axvline(mean_treatment, color='red', linestyle='dashed', linewidth=2)\naxes[1].set_title('Treatment Group (Donors Only)')\naxes[1].set_xlabel('Donation Amount')\naxes[1].text(mean_treatment + 1, axes[1].get_ylim()[1] * 0.8,\n             f'Mean: ${mean_treatment:.2f}', color='red')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThese histograms show that the distribution of donation amounts is right-skewed in both groups — many people donate small amounts, while a few give very large gifts.\nThe mean donation is slightly higher in the control group ($45.54) than in the treatment group ($43.87) However, as shown in the regression earlier, this difference is not statistically significant. The presence of a matching gift motivates more people to give, but does not clearly increase gift size among those who do donate."
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse."
  },
  {
    "objectID": "projects/project1/index.html#introduction",
    "href": "projects/project1/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse."
  },
  {
    "objectID": "projects/project1/index.html#abstract",
    "href": "projects/project1/index.html#abstract",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Abstract",
    "text": "Abstract\nThis project seeks to replicate and interpret results from Karlan and List’s (2007) influential field experiment, which examined whether matching donations increase charitable giving. Over 50,000 prior donors were randomly assigned to receive direct mail with either no matching offer (control) or one of three matching grant treatments: $1:$1, $2:$1, or $3:$1.\nThe goal of this replication is to reproduce the study’s main empirical findings using the original dataset, explore the impact of different match ratios on both response rates and donation amounts, and provide insights relevant for fundraising practitioners."
  },
  {
    "objectID": "projects/project1/index.html#data",
    "href": "projects/project1/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nWe use the dataset made public by the authors, consisting of 50,083 prior donors who were randomly assigned into different treatment groups. The dataset contains variables indicating treatment status, donation behavior, suggested amounts, demographics, and political/geographic characteristics.\n\n\nSample Overview\n\nObservations: 50,083\nTreatments:\n\nControl\nMatching grants: $1:$1, $2:$1, $3:$1\n\nKey Outcomes:\n\ngave: whether the donor gave anything\namount: donation amount (if any)\n\nExample Variables:\n\nsize: suggested donation size (Unstated, $50, $100, etc.)\nredcty: lives in a red county\nhomestate: same state as charity ### Load and Preview the Data\n\n\n\nimport pandas as pd\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nWe test three pre-treatment variables: - Months since last donation (mrm2) - Highest previous contribution (hpa) - Number of prior donations (freq)\nThese variables should be similar across treatment and control groups if randomization was successful. We perform both t-tests and linear regressions for robustness. The table below summarizes the results.\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom scipy import stats\n\nbalance_vars = {\n    'Months Since Last Donation': 'mrm2',\n    'Highest Previous Contribution': 'hpa',\n    'Number of Prior Donations': 'freq'\n}\n\n# T-tests and OLS regressions\nttest_results = {}\nols_results = {}\n\nfor label, var in balance_vars.items():\n    control_vals = df[df['treatment'] == 0][var].dropna()\n    treatment_vals = df[df['treatment'] == 1][var].dropna()\n    t_stat, p_val = stats.ttest_ind(control_vals, treatment_vals, equal_var=False)\n    ttest_results[label] = {'t_stat': t_stat, 'p_val': p_val}\n\n    model = smf.ols(f\"{var} ~ treatment\", data=df).fit()\n    coef = model.params['treatment']\n    pval = model.pvalues['treatment']\n    ols_results[label] = {'coef': coef, 'p_val': pval}\n\n# Format for display\nbalance_summary = pd.DataFrame({\n    'Variable': list(balance_vars.keys()),\n    'T-test p-value': [ttest_results[v]['p_val'] for v in balance_vars],\n    'OLS coef on treatment': [ols_results[v]['coef'] for v in balance_vars],\n    'OLS p-value': [ols_results[v]['p_val'] for v in balance_vars]\n})\n\nbalance_summary\n\n\n\n\n\n\n\n\nVariable\nT-test p-value\nOLS coef on treatment\nOLS p-value\n\n\n\n\n0\nMonths Since Last Donation\n0.904855\n0.013686\n0.904886\n\n\n1\nHighest Previous Contribution\n0.331840\n0.637075\n0.345099\n\n\n2\nNumber of Prior Donations\n0.911740\n-0.011979\n0.911702\n\n\n\n\n\n\n\nThe balance test confirms that randomization worked as intended. Across the three pre-treatment variables — months since last donation, highest previous contribution, and number of prior donations — none show statistically significant differences between treatment and control groups at the 5% level. ﻿ This supports the internal validity of the experiment: any observed effects in giving behavior are unlikely to be due to baseline differences."
  },
  {
    "objectID": "projects/project1/index.html#experimental-results",
    "href": "projects/project1/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nMatching Donations Increase Giving Probability\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\nWe compare the proportion of individuals who donated between the treatment group and the control group. This helps us understand whether the announcement of a matching gift increases the likelihood of donating.\n\nimport matplotlib.pyplot as plt\n\n# Calculate donation rates by group\ndonation_rates = df.groupby('treatment')['gave'].mean()\ndonation_rates.index = ['Control', 'Treatment']\n\n# Create bar plot\nfig, ax = plt.subplots(figsize=(6, 4))\nbars = ax.bar(donation_rates.index, donation_rates.values, width=0.5, color=['#4C72B0', '#55A868'])\n\n# Add percentage labels\nfor bar in bars:\n    height = bar.get_height()\n    ax.text(bar.get_x() + bar.get_width() / 2, height + 0.002,\n            f'{height:.2%}', ha='center', va='bottom', fontsize=10)\n\n# Formatting\nax.set_ylabel('Proportion Donated')\nax.set_title('Effect of Matching Gift on Donation Rate')\nax.set_ylim(0, max(donation_rates.values) + 0.03)\nax.grid(axis='y', linestyle='--', alpha=0.5)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe chart shows that individuals in the treatment group donated at a rate of 2.20%, compared to 1.79% in the control group — an increase of approximately 23% in relative terms. This result suggests that the announcement of a matching gift offer increases donor engagement, likely because donors feel their contribution has greater impact.\nThis initial analysis replicates the paper’s key finding: matching incentives effectively nudge donors into action.\n\n\nStatistical Significance: T-test and Linear Regression\nWe test whether the observed difference in donation behavior is statistically significant, using both a t-test and a bivariate regression.\n\nimport pandas as pd\nfrom scipy.stats import ttest_ind\ncontrol = df[df[\"treatment\"] == 0][\"gave\"]\ntreatment = df[df[\"treatment\"] == 1][\"gave\"]\nt_stat, p_val = ttest_ind(treatment, control, equal_var=False)\nprint(f\"\"\"\nT-Test Summary\n\n- T-statistic**: {t_stat:.4f}\n- P-value**: {p_val:.4f}\n\"\"\")\n\n\nT-Test Summary\n\n- T-statistic**: 3.2095\n- P-value**: 0.0013\n\n\n\n\nimport statsmodels.formula.api as smf\n\n# Fit the model\nmodel = smf.ols(\"gave ~ treatment\", data=df).fit()\ncoef = model.params[\"treatment\"]\npval = model.pvalues[\"treatment\"]\nci_low, ci_high = model.conf_int().loc[\"treatment\"]\nbaseline = model.params[\"Intercept\"]\n\nprint(f\"\"\"\nKey Findings\n\n- Baseline Donation Rate (Control Group)**: {baseline:.2%}\n- Treatment Effect**: +{coef:.2%}\n- P-value**: {pval:.4f}\n- 95% Confidence Interval**: [{ci_low:.2%}, {ci_high:.2%}]\n\"\"\")\n\n\nKey Findings\n\n- Baseline Donation Rate (Control Group)**: 1.79%\n- Treatment Effect**: +0.42%\n- P-value**: 0.0019\n- 95% Confidence Interval**: [0.15%, 0.68%]\n\n\n\nBoth tests lead to the same conclusion:\nThe t-test indicates a statistically significant difference in mean donation rates between treatment and control (p-value &lt; 0.01). The regression coefficient on treatment is +0.0042, indicating that individuals in the treatment group were 0.42 percentage points more likely to donate, which is about a 23% increase over the control group mean of 1.79%. This finding is statistically significant (p = 0.002), and replicates the original result in Table 2a Panel A of Karlan and List (2007).\nBehavioral Insight When individuals are told that their contribution will be matched, they perceive their action as more impactful. This increases their willingness to give, even if the absolute probability of donation remains low. Matching gifts operate not only as a financial lever but also as a psychological motivator, increasing perceived effectiveness.\n\n\nProbit Model with Marginal Effects\nWhile the probit coefficient on treatment was 0.087, that number cannot be directly interpreted as a change in probability. So, we compute the marginal effect of treatment.\n\nprobit_model = sm.Probit(df['gave'], sm.add_constant(df['treatment'])).fit()\nmarginal_effects = probit_model.get_margeff()\nmarginal_effects.summary()\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\n\nProbit Marginal Effects\n\n\nDep. Variable:\ngave\n\n\nMethod:\ndydx\n\n\nAt:\noverall\n\n\n\n\n\n\n\n\n\ndy/dx\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\ntreatment\n0.0043\n0.001\n3.104\n0.002\n0.002\n0.007\n\n\n\n\n\nThe marginal effect of treatment is approximately 0.004, which means that receiving a matching offer increased the probability of donation by 0.4 percentage points — exactly what the original paper reports using a linear probability model. In this way, the Probit model gives us both a robust theoretical approach and a practically interpretable result."
  },
  {
    "objectID": "projects/project1/index.html#do-higher-matching-ratios-boost-giving",
    "href": "projects/project1/index.html#do-higher-matching-ratios-boost-giving",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Do Higher Matching Ratios Boost Giving?",
    "text": "Do Higher Matching Ratios Boost Giving?\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nWe use a series of t-tests to compare whether people are more likely to donate under higher match ratios ($2:$1 or $3:$1) compared to the standard $1:$1 match ratio. This allows us to test whether larger matching incentives increase giving behavior.\n\nfrom scipy.stats import ttest_ind\n\n# Only include treatment group\ndf_match = df[df['treatment'] == 1]\n\n# Subgroup donation outcomes\ngave_1_1 = df_match[df_match['ratio'] == 1]['gave']\ngave_2_1 = df_match[df_match['ratio'] == 2]['gave']\ngave_3_1 = df_match[df_match['ratio'] == 3]['gave']\n\n# Compute means\nmean_1_1, mean_2_1, mean_3_1 = gave_1_1.mean(), gave_2_1.mean(), gave_3_1.mean()\n\n# T-tests: compare to 1:1\nttest_2v1 = ttest_ind(gave_2_1, gave_1_1, equal_var=False)\nttest_3v1 = ttest_ind(gave_3_1, gave_1_1, equal_var=False)\n\n# Output results\nprint(f\"Mean donation rates — 1:1: {mean_1_1:.4%}, 2:1: {mean_2_1:.4%}, 3:1: {mean_3_1:.4%}\")\nprint(\"2:1 vs 1:1 p-value:\", round(ttest_2v1.pvalue, 4))\nprint(\"3:1 vs 1:1 p-value:\", round(ttest_3v1.pvalue, 4))\n\nMean donation rates — 1:1: 2.0749%, 2:1: 2.2633%, 3:1: 2.2733%\n2:1 vs 1:1 p-value: 0.3345\n3:1 vs 1:1 p-value: 0.3101\n\n\nDespite slightly higher average donation rates in the 2:1 and 3:1 groups, neither difference is statistically significant. In other words, larger match offers did not significantly outperform the $1:$1 offer.\nIn essence, the act of announcing a match — any match — appears to be the key driver of increased giving. Donors respond to the presence of a match, not the generosity of its ratio. Once the match “feels impactful enough,” increasing the multiplier adds little marginal psychological value. This confirms the authors’ interpretation in the paper: “Larger match ratios had no additional impact.” (Page 8, Karlan & List 2007)"
  },
  {
    "objectID": "projects/project1/index.html#regression-match-ratio-effects-on-giving",
    "href": "projects/project1/index.html#regression-match-ratio-effects-on-giving",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Regression: Match Ratio Effects on Giving",
    "text": "Regression: Match Ratio Effects on Giving\nTo further assess whether larger match ratios increase donation behavior, we estimate a regression model where we compare 2:1 and 3:1 match rates to the baseline 1:1 match rate.\n\nimport statsmodels.formula.api as smf\n\ndf_match = df[df[\"treatment\"] == 1]\n\nmodel = smf.ols(\"gave ~ ratio2 + ratio3\", data=df_match).fit()\n\ncoef = model.params\npval = model.pvalues\nci = model.conf_int()\n\nprint(f\"\"\"\nKey Results\n\n- Baseline Donation Rate (1:1 match): {coef['Intercept']:.2%}\n- 2:1 Match Effect (ratio2): {coef['ratio2']:.2%} (p = {pval['ratio2']:.3f}, 95% CI: [{ci.loc['ratio2', 0]:.2%}, {ci.loc['ratio2', 1]:.2%}])\n- 3:1 Match Effect (ratio3): {coef['ratio3']:.2%} (p = {pval['ratio3']:.3f}, 95% CI: [{ci.loc['ratio3', 0]:.2%}, {ci.loc['ratio3', 1]:.2%}])\n\"\"\")\n\n\nKey Results\n\n- Baseline Donation Rate (1:1 match): 2.07%\n- 2:1 Match Effect (ratio2): 0.19% (p = 0.338, 95% CI: [-0.20%, 0.57%])\n- 3:1 Match Effect (ratio3): 0.20% (p = 0.313, 95% CI: [-0.19%, 0.58%])\n\n\n\nThis regression estimates how larger matching ratios affect the probability of donating. The intercept (0.0207) represents the average donation rate for the 1:1 match group — about 2.1%. The coefficient on ratio2 (2:1 match) is +0.0019, and the coefficient on ratio3 (3:1 match) is +0.0020. However, both of these coefficients are statistically insignificant (p-values &gt; 0.3), meaning that we cannot rule out that they are due to random chance.\nThese results reinforce what we observed in the t-tests and what Karlan & List (2007) emphasize in their paper: “Larger match ratios had no additional impact.” (Page 8)\nPeople are clearly responsive to the existence of a matching offer, but not its size. The match seems to function more like a binary psychological cue — a “yes/no” motivator — rather than a finely calibrated economic incentive.\nIn practice, this means that offering a 2:1 or 3:1 match does not significantly improve participation beyond what a 1:1 match already achieves. For fundraisers, this suggests that costlier match ratios may not provide additional return in response rate.\n\nResponse Rate Differences by Match Ratio\nWe now compute the response rate difference (i.e., difference in donation probability) between the match ratios using two methods: 1. Directly from the data 2. Using the fitted coefficients from the regression\n\nMethod 1: Directly from the data\n\n# Mean donation rates by ratio\nmean_1_1 = df_match[df_match['ratio'] == 1]['gave'].mean()\nmean_2_1 = df_match[df_match['ratio'] == 2]['gave'].mean()\nmean_3_1 = df_match[df_match['ratio'] == 3]['gave'].mean()\n\ndiff_2v1 = mean_2_1 - mean_1_1\ndiff_3v2 = mean_3_1 - mean_2_1\n\nprint(\"Response rate (2:1 - 1:1):\", round(diff_2v1, 4))\nprint(\"Response rate (3:1 - 2:1):\", round(diff_3v2, 4))\n\nResponse rate (2:1 - 1:1): 0.0019\nResponse rate (3:1 - 2:1): 0.0001\n\n\n\n\nMethod 2: Using regression coefficients\nRecall from the earlier regression:\nIntercept (1:1): 0.0207\nratio2 coefficient: +0.0019\nratio3 coefficient: +0.0020\nSo:\n2:1 - 1:1 = 0.0019\n3:1 - 2:1 = 0.0020 - 0.0019 = 0.0001\nBoth approaches yield nearly identical results:\nMoving from 1:1 to 2:1 increases the response rate by only 0.19–0.20 percentage points\nMoving from 2:1 to 3:1 increases the response rate by just 0.01 percentage points\nThese differences are statistically insignificant and extremely small. This reinforces our earlier conclusion that larger match ratios do not meaningfully increase participation. The psychological presence of a match seems to matter more than its actual size."
  },
  {
    "objectID": "projects/project1/index.html#size-of-charitable-contribution",
    "href": "projects/project1/index.html#size-of-charitable-contribution",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Size of Charitable Contribution",
    "text": "Size of Charitable Contribution\nIn this subsection, we analyze whether the presence of a matching offer influences the size of the charitable donation, conditional on a donation being made.\nWe compare donation amounts between treatment and control groups using both a t-test and a bivariate linear regression.\n\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Separate groups\namount_control = df[df['treatment'] == 0]['amount']\namount_treatment = df[df['treatment'] == 1]['amount']\n\n# T-test\nt_stat, p_val = ttest_ind(amount_treatment, amount_control, equal_var=False)\n\n# Regression\nmodel_amount = smf.ols(\"amount ~ treatment\", data=df).fit()\n\n# Extract results\ncoef = model_amount.params\npvals = model_amount.pvalues\nci = model_amount.conf_int()\nprint(f\"\"\"\nT-Test Result\n\n- T-statistic**: {t_stat:.4f}\n- P-value**: {p_val:.4f}\n\nRegression Summary\n\n- Baseline Amount (Control Group)**: ${coef['Intercept']:.2f}\n- Treatment Effect**: +${coef['treatment']:.2f}\n- P-value: {pvals['treatment']:.3f}\n- 95% CI: [${ci.loc['treatment', 0]:.2f}, ${ci.loc['treatment', 1]:.2f}]\n\"\"\")\n\n\nT-Test Result\n\n- T-statistic**: 1.9183\n- P-value**: 0.0551\n\nRegression Summary\n\n- Baseline Amount (Control Group)**: $0.81\n- Treatment Effect**: +$0.15\n- P-value: 0.063\n- 95% CI: [$-0.01, $0.32]\n\n\n\nThe t-test yields a p-value of approximately 0.055, just above the standard 0.05 significance threshold. The regression model estimates that individuals in the treatment group give on average $0.15 more, with a p-value of 0.063. Both results suggest a positive but marginally insignificant effect.\nThese results provide an important nuance: While the matching offer increases the likelihood of giving, its effect on how much people give is less certain.\nSome individuals may be nudged into donating, but the size of the gift remains unaffected — or possibly even lower due to anchoring or tokenism (giving just enough to meet a perceived match).\nThis distinction underscores an important insight:\nParticipation and generosity may be driven by different behavioral mechanisms. Matching incentives are effective in getting people to act, but don’t necessarily increase the amount they give once they decide to give. From a fundraising perspective, this tells us that match incentives work best for increasing reach, not necessarily for maximizing revenue per donor."
  },
  {
    "objectID": "projects/project1/index.html#conditional-on-donating-did-people-give-more",
    "href": "projects/project1/index.html#conditional-on-donating-did-people-give-more",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Conditional on Donating: Did People Give More?",
    "text": "Conditional on Donating: Did People Give More?\nTo investigate whether the matching offer influences how much people give, we now restrict our analysis to only those individuals who made a donation. This allows us to analyze donation amounts conditional on giving.\n\n# Subset to donors only\ndf_positive = df[df[\"gave\"] == 1]\n\n# Run regression\nmodel_conditional = smf.ols(\"amount ~ treatment\", data=df_positive).fit()\n\n# Extract results\ncoef = model_conditional.params\npval = model_conditional.pvalues\nci = model_conditional.conf_int()\nprint(f\"\"\"\nRegression Summary\n\n- Baseline Donation (Control Group)**: ${coef['Intercept']:.2f}\n- Treatment Effect**: {coef['treatment']:+.2f}\n- P-value: {pval['treatment']:.3f}\n- 95% Confidence Interval: [{ci.loc['treatment', 0]:.2f}, {ci.loc['treatment', 1]:.2f}]\n\"\"\")\n\n\nRegression Summary\n\n- Baseline Donation (Control Group)**: $45.54\n- Treatment Effect**: -1.67\n- P-value: 0.561\n- 95% Confidence Interval: [-7.30, 3.97]\n\n\n\nThis regression estimates how the presence of a matching offer affects the size of the donation, among those who chose to give. The intercept (45.54) represents the average donation in the control group. The coefficient on treatment (-1.67) suggests that treated individuals gave slightly less on average — about $1.67 — but this effect is not statistically significant (p = 0.561).\nDoes This Have a Causal Interpretation?\nNo — and caution is warranted. While the original treatment assignment was randomized, this regression is conditional on donation behavior, which is a post-treatment variable. By analyzing only those who gave, we introduce selection bias — the two groups (treatment vs. control) are no longer directly comparable.\nMatching offers increase the probability of giving, as we’ve shown earlier. But among those who give, there is no significant difference in how much they donate. This suggests that matching incentives motivate action, but may not influence the donation amount once the decision to give is made. From a behavioral standpoint, this distinction is critical:\nParticipation and generosity are driven by different psychological forces. Matching works well to prompt giving — but not necessarily larger gifts.\nIf the goal is to maximize the number of donors, matching offers are effective. If the goal is to increase the average gift size, you may need a different strategy — such as social comparison, goal framing, or tiered benefits.\n\nDistribution of Donation Amounts (Donors Only)\nWe now visualize the distribution of donation amounts only among those who gave, separately for the treatment and control groups.\n\nimport matplotlib.pyplot as plt\n\ndonated_control = df[(df['gave'] == 1) & (df['treatment'] == 0)]['amount']\ndonated_treatment = df[(df['gave'] == 1) & (df['treatment'] == 1)]['amount']\n\nmean_control = donated_control.mean()\nmean_treatment = donated_treatment.mean()\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\n# Control group\naxes[0].hist(donated_control, bins=20, color='skyblue', edgecolor='black')\naxes[0].axvline(mean_control, color='red', linestyle='dashed', linewidth=2)\naxes[0].set_title('Control Group (Donors Only)')\naxes[0].set_xlabel('Donation Amount')\naxes[0].set_ylabel('Frequency')\naxes[0].text(mean_control + 1, axes[0].get_ylim()[1] * 0.8,\n             f'Mean: ${mean_control:.2f}', color='red')\n\n# Treatment group\naxes[1].hist(donated_treatment, bins=20, color='lightgreen', edgecolor='black')\naxes[1].axvline(mean_treatment, color='red', linestyle='dashed', linewidth=2)\naxes[1].set_title('Treatment Group (Donors Only)')\naxes[1].set_xlabel('Donation Amount')\naxes[1].text(mean_treatment + 1, axes[1].get_ylim()[1] * 0.8,\n             f'Mean: ${mean_treatment:.2f}', color='red')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThese histograms show that the distribution of donation amounts is right-skewed in both groups — many people donate small amounts, while a few give very large gifts.\nThe mean donation is slightly higher in the control group ($45.54) than in the treatment group ($43.87) However, as shown in the regression earlier, this difference is not statistically significant. The presence of a matching gift motivates more people to give, but does not clearly increase gift size among those who do donate."
  },
  {
    "objectID": "projects/project1/index.html#simulation-experiment",
    "href": "projects/project1/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nTo simulate the LLN, we:\n\nDraw 10,000 Bernoulli samples from each group\nCalculate the difference in outcomes for each simulated pair\nPlot the cumulative average of the differences\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set probabilities\np_control = 0.018\np_treatment = 0.022\nn_draws = 10000\nnp.random.seed(42)\n\n# Simulate\ncontrol_draws = np.random.binomial(1, p_control, n_draws)\ntreatment_draws = np.random.binomial(1, p_treatment, n_draws)\n\n# Difference vector\ndifferences = treatment_draws - control_draws\ncumulative_avg_diff = np.cumsum(differences) / np.arange(1, n_draws + 1)\n\n# Plot\ntrue_diff = p_treatment - p_control\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg_diff, label='Cumulative Avg. of Differences', color='orange')\nplt.axhline(true_diff, color='red', linestyle='--', label='True Difference (0.004)')\nplt.title(\"Law of Large Numbers Simulation: Convergence to True Difference\")\nplt.xlabel(\"Simulation Iteration\")\nplt.ylabel(\"Difference in Donation Probability\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe simulation shows that the cumulative average of the differences converges to the true value of 0.004, which is the expected treatment effect. This is a visual and intuitive demonstration of the Law of Large Numbers: with more data, our sample statistics converge to population parameters.\nThis validates the logic behind the t-test and confirms why large samples allow for reliable estimation of small effects — just like in Karlan & List (2007), where a small increase in giving (from 1.8% to 2.2%) was detected across a large sample.\n\n\nCentral Limit Theorem\nTo visualize the Central Limit Theorem, we simulate 1,000 experiments for each of four sample sizes: 50, 200, 500, and 1000. In each simulation, we:\n\nDraw n observations from a Bernoulli(p=0.018) distribution (control group)\nDraw n from a Bernoulli(p=0.022) distribution (treatment group)\nCalculate the difference in sample means (treatment - control)\nRepeat 1,000 times and plot the histogram of these average differences\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.flatten()\n\nfor idx, n in enumerate(sample_sizes):\n    avg_diffs = [] \n    for _ in range(n_simulations):\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        diff = treatment_sample.mean() - control_sample.mean()\n        avg_diffs.append(diff)\n\n  \n    axes[idx].hist(avg_diffs, bins=30, color='skyblue', edgecolor='black')\n    axes[idx].axvline(0, color='red', linestyle='--', label='Zero')\n    axes[idx].set_title(f\"Sample Size = {n}\")\n    axes[idx].set_xlabel(\"Avg. Difference (Treatment - Control)\")\n    axes[idx].set_ylabel(\"Frequency\")\n    axes[idx].legend()\n\nplt.suptitle(\"Central Limit Theorem Simulation: Sampling Distributions of Avg. Differences\", fontsize=14)\nplt.tight_layout(rect=[0, 0, 1, 0.96])\nplt.show()\n\n\n\n\n\n\n\n\nThese histograms show that:\nAs sample size increases, the distribution of average differences becomes tighter and more symmetric For small sample sizes (e.g., n = 50), the histogram is more spread out and zero often appears near the center For larger sample sizes (n = 500 or 1000), the distribution concentrates around the true mean difference (~0.004), and zero moves closer to the edge or tail This behavior demonstrates the Central Limit Theorem in action:\nEven though the original data (Bernoulli) is highly skewed, the sampling distribution of the mean difference becomes approximately normal, and its variance shrinks with larger n.\nThis validates why Karlan & List’s experiment was able to detect a small effect (2.2% vs 1.8%) — their large sample size ensured that sampling variation wouldn’t drown out the true effect."
  }
]